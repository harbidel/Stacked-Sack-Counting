# -*- coding: utf-8 -*-
"""Stacked Bag.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15diMbVB-ZViD0CuqoLosTISFiQlURPKl
"""

!pip install tensorflow numpy opencv-python-headless

pip install colab-convert

pip install --upgrade tensorflow

#from tensorflow.keras.layers import LeakyReLU

pip install keras-applications

!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg

import urllib.request
import os

# Download YOLOv3 weights file
if not os.path.exists('yolov3.weights'):
    urllib.request.urlretrieve('https://pjreddie.com/media/files/yolov3.weights', 'yolov3.weights')

# Convert YOLOv3 weights file to Keras model file
if not os.path.exists('yolov3.h5'):
    !python convert.py yolov3.cfg yolov3.weights yolov3.h5

import tensorflow as tf

# Load YOLOv3 model from Keras model file
model = tf.keras.models.load_model('yolov3.h5', compile=False)

# Freeze pre-trained layers
for layer in model.layers[:-3]:
    layer.trainable = False

import tensorflow as tf

# define input layers
input1 = tf.keras.layers.Input(shape=(None, None, 3))
input2 = tf.keras.layers.Input(shape=(None, None, 3))
input3 = tf.keras.layers.Input(shape=(None, None, 3))

# concatenate inputs into a single tensor
inputs = tf.keras.layers.concatenate([input1, input2, input3])

# apply global average pooling layer
x = tf.keras.layers.GlobalAveragePooling2D()(inputs)

# add custom layers for fine-tuning
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dense(1, activation='sigmoid')(x)

# create fine-tuned model
fine_tuned_model = tf.keras.models.Model(inputs=[input1, input2, input3], outputs=x)

#!git clone https://github.com/qqwweee/keras-yolo3.git

# Specify input shape
input_shape = (416, 416, 3)
fine_tuned_model.build(input_shape)

# Compile the model
fine_tuned_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

import requests

# Define URLs of images to download
image_urls = ['https://st.depositphotos.com/1031223/3245/i/600/depositphotos_32451819-stock-photo-stacked-sugar-bag.jpg',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRC2jZ3ayVLhRfbzvyT5Tcl35tAC365DIcWBrARv2voouf5TAlZ-c-ahqYOpZt_4Cs7u-0&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRuYOUlll_S14gHoh8sW4iJuqY1qXrL9mgCkDNfJGQW1AqA_OOy0IYrJGQ2It6vhOGgSKo&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ7hqdS8heGlbvMCmu5RU40P043PTp5ONK422QQq76o9VnrQdf22WGnwMWKlKaF_MLfpxc&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQbt0EdJAmYMK67aEPwqeD-mYj4I3aSnfn-lg&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTraWDxHChvgXtsv6dHoz2Gq_D5pkXdya88dA&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRt-05UOW9g8u_DQvwlkC_8uK456CA2I588Stgsx6nJ6IZm6TDOS5xMEh_12OAGqpU5GI4&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTRpLPfDyMqzYpnJ8wh4WAccM1ka_Ki2BCmj47naEI7fLIo6rRmCSdUcFVkDjZz0fsblKo&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQtlPtQYmPv2uCYDWQ9lDouXlCspAAkWMxz3Q&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRQp2jjUqVGyvRQKHW5y3BF2hS4hcY0i66v0Q&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSjVyKBef5wpYcu6RttCkJcdGeYciSEInsEZHFA04yW10der7ZfGoouz_Mp8ve5NrmjBXY&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQc5uQ8FsUb-Afb3LjQKLm1tgUW6usIDw7b0U9NGyD7EPzf5BlWrhKOEdOLEOoYfd2j328&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQsxHnaizrrZ5FAF0mKCEO9VFG4MMxlZTcsGApUKcj4cxHx2WcjcZZkZM-YLLWATgnPUVM&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS6qvFLj9RK8NB73dqNmex2gCk0PUOPlC2bcCn0Lm89IBEdeOdGLD_5HWkUwYzjIZAUOzY&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSXLwxw5X2-vZ1KYT_mO2V-hzfhBqjmQHDgvdCCPKSq2HLR5sDkSyI_xduaFNLZch37fmQ&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRoWZ6cHeYPpISOYGQDXRJ3qV8KHE48vGGKiIZ6iGZe2eaRhUUxays4n9CDMNXHKIFLhjo&usqp=CAU',
'https://thumbs.dreamstime.com/b/bags-sugar-freight-trolley-211009763.jpg',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSZPSK1vc_IVFiCy_qVJPQ2cVxch3Xi-7rOOs5ZIG85q9yyPRwz6JKkSuSDwMovDuM8qrQ&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSckDz4KRVNvxSIN0VIbKBgxGMPb-QSNguIcBM3yjemZtkpUAFYh6Jt6KwzZI3A71MPlhM&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQX7qUEIVYmdLcJKlmsg-wDtnEjGcwBbhWrOg&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRRcyNT8neiDIOKFUzOxjdQ8xm3eT9efOfs8cA9IT0U5QsgF1BSZRZkRmMHxKo4GqNMkdo&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQN0UqyrLeOmeRbqPdENfofAqYmrma2NtCIb10wFy1YGUNG044vmKGXWxlf-Zf_yNeMUX8&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRlCfiIdTBlkH_VhZ4AjCmwPRH4U3wYSGdnwQBgnR-v359gwRV-KgPRGszakEj5RnNZppk&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSJTFo-sjy1-WEk5bYEAzbAFrIMW_3GYKwwM1UyCtb7EQre9aIhHLeOG4IJ8Xdxvu67ZNk&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQNA3BW8LuhzRR1089bWok7pC4xclgq0n43UA&usqp=CAU',
'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS4Bi5D8Tjx6vN10gYjRscO0p_hsVdn7usKLQ&usqp=CAU'
]

# Create directory for images (if it doesn't already exist)
if not os.path.exists("images"):
    os.makedirs("images")

# Download and save images
for i, url in enumerate(image_urls):
    try:
        # Send GET request for image
        response = requests.get(url)
        # Write image to file
        with open(f"images/sack_{i+1}.jpg", "wb") as f:
            f.write(response.content)
    except:
        print(f"Could not download image from {url}")

import os
import pandas as pd
import numpy as np
import cv2
'''
# Set path to CSV file and image directory
annotations_path = "annotations.csv"
image_dir = "images/"

# Load annotations from CSV file
annotations = pd.read_csv(annotations_path)

# Create training dataset
X_train = []
y_train = []
for i, row in annotations.iterrows():
    # Load image
    img_path = os.path.join(image_dir, row['filename'])
    img = cv2.imread(img_path)
    if img is not None:
        # Resize image to (416, 416)
        img = cv2.resize(img, (416, 416))
        # Convert image to RGB format
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        # Normalize pixel values to [0, 1]
        img = img / 255.0
        # Add image to training dataset
        X_train.append(img)
        y_train.append(row['label'])
    else:
        print(f"Could not read image {img_path}")

X_train = np.array(X_train)
y_train = np.array(y_train)
'''

# Set path to CSV file and image directory
annotations_path = "annotations.csv"
image_dir = "images/"

# Load annotations from CSV file
annotations = pd.read_csv(annotations_path)

# Create training dataset
X_train = []
y_train = []
for i, row in annotations.iterrows():
    # Load image
    img_path = os.path.join(image_dir, row['filename'])
    img = cv2.imread(img_path)
    if img is not None:
        # Resize image to (416, 416)
        img = cv2.resize(img, (416, 416))
        # Convert image to RGB format
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        # Normalize pixel values to [0, 1]
        img = img / 255.0
        # Add image to training dataset
        X_train.append([img, img, img])  # repeat the same image 3 times
        y_train.append(row['label'])
    else:
        print(f"Could not read image {img_path}")

X_train = [np.array(X_train)[:, i] for i in range(3)]  # separate the 3 images
y_train = np.array(y_train)

X_train

y_train

fine_tuned_model.fit(X_train, y_train, batch_size=16, epochs=10)

annotations_test = pd.read_csv('annotations_test.csv')
X_test = []
y_test = []
for i, row in annotations_test.iterrows():
    img = cv2.imread(row['filename'])
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (416, 416))
    img = img / 255.0
    X_test.append(img)
    y_test.append(row['num_bags'])
X_test = np.array(X_test)
y_test = np.array(y_test)

results = fine_tuned_model.evaluate(X_test, y_test)
print('Test Loss:', results[0])
print('Test Accuracy:', results[1])

fine_tuned_model.save('bag_estimator_model.h5')